{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10886, 12)\n",
      "train is \n",
      "(10886, 10)\n",
      "labels train are \n",
      "(10886,)\n",
      "test is \n",
      "(6493, 10)\n",
      "Number of Negative values predicted are  24\n",
      "trainSplit is \n",
      "(8708, 10)  and testSplit is \n",
      "(2178, 10)\n",
      "ypred is \n",
      "[  45.96415231   45.28381731  185.60055065 ...,  137.16521297  130.73808505\n",
      "   94.32587411]\n",
      "test split is \n",
      "[ 19  19  68 ..., 168 129  88]\n",
      "the loss is  0.639249877172\n",
      "testd shape is  (6493, 10)\n",
      "Feature Ranking\n",
      "\n",
      "1. feature 8 Hour (0.489551)\n",
      "2. feature 2 workingday (0.117948)\n",
      "3. feature 6 humidity (0.097533)\n",
      "4. feature 4 temp (0.079195)\n",
      "5. feature 9 DayOfWeek (0.073352)\n",
      "6. feature 5 atemp (0.047408)\n",
      "7. feature 0 season (0.043905)\n",
      "8. feature 3 weather (0.023082)\n",
      "9. feature 7 windspeed (0.020679)\n",
      "10. feature 1 holiday (0.007349)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:102: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:104: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:105: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:106: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import copy\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import csv\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "dateparse=lambda x:pd.datetime.strptime(x,'%Y-%m-%d %H:%M:%S')\n",
    "train=pd.read_csv('train.csv',parse_dates=['datetime'],date_parser=dateparse)\n",
    "test=pd.read_csv('test.csv',parse_dates=['datetime'],date_parser=dateparse)\n",
    "\n",
    "#test['windspeed']=np.log(test['windspeed']+1)\n",
    "#train['windspeed']=np.log(train['windspeed']+1)\n",
    "print train.shape\n",
    "\n",
    "def extractFeaturesTrain(data):\n",
    "    #print 'data is ',data\n",
    "    data['Hour']=data.datetime.dt.hour\n",
    "    data['DayOfWeek']=data.datetime.dt.dayofweek\n",
    "    #data['Month']=data.datetime.dt.month\n",
    "    labels=data['count']\n",
    "    train_years=data.datetime.dt.year\n",
    "    train_months=data.datetime.dt.month\n",
    "    data=data.drop(['datetime','count','casual','registered'], axis = 1)\n",
    "    \n",
    "    return np.array(data),np.array(labels),np.array(train_years),np.array(train_months),(data.columns.values)\n",
    "\n",
    "def extractFeaturesTest(data):\n",
    "    \n",
    "    data['Hour']=data.datetime.dt.hour\n",
    "    data['DayOfWeek']=data.datetime.dt.dayofweek\n",
    "    #data['Month']=data.datetime.dt.month\n",
    "    test_years=data.datetime.dt.year\n",
    "    test_months=data.datetime.dt.month\n",
    "    data=data.drop(['datetime'], axis = 1)\n",
    "    return np.array(data),np.array(test_years),np.array(test_months)\n",
    "    \n",
    "train2=copy(train)\n",
    "test2=copy(test)\n",
    "test=np.array(test)\n",
    "#print 'train2 is ',train2\n",
    "traind,labelsTrain,train_years,train_months,headers=extractFeaturesTrain(train2)\n",
    "testd,test_years,test_months=extractFeaturesTest(test2)\n",
    "\n",
    "submit=np.array((test.shape[0],2))\n",
    "\n",
    "#train.to_csv('Remodeled Train.csv')\n",
    "train=np.array(train)\n",
    "print 'train is \\n',traind.shape\n",
    "print 'labels train are \\n',labelsTrain.shape\n",
    "print 'test is \\n',testd.shape\n",
    "\n",
    "def findLocations(year,month):\n",
    "    locs=[]\n",
    "    for i in range(0,test.shape[0]):\n",
    "        if(test[i][0].year==year and test[i][0].month==month):\n",
    "            locs.append(i)\n",
    "        \n",
    "    return locs\n",
    "        \n",
    "def findValidDates(year,month):\n",
    "    locs=[]\n",
    "    for i in range(0,train.shape[0]):\n",
    "        if(train[i][0].year<=year and train[i][0].month<=month):\n",
    "            locs.append(i)\n",
    "    \n",
    "    return locs\n",
    "            \n",
    "'''for i in set(test_years):\n",
    "    for j in set(test_months):\n",
    "        print 'Year : ',i,' month ',j:\n",
    "            testLocs=findLocations(i,j)\n",
    "            testSubset=testd[testLocs]\n",
    "            \n",
    "            trainLocs=findValidDates(i,j)\n",
    "            trainSubset=traind[trainLocs]'''\n",
    "            \n",
    "def findLoss(gold,predicted):\n",
    "    loss=0\n",
    "    for i in range(gold.shape[0]):\n",
    "        loss+=(np.log(predicted[i]+1) -np.log(gold[i]+1))**2\n",
    "        \n",
    "    loss=loss/gold.shape[0]\n",
    "    #print 'loss is ',loss,' y_pred is ',predicted[i]\n",
    "    return np.sqrt(loss)\n",
    "\n",
    "def replaceNegaticeValuesWithZeroAndCountThem(ypred):\n",
    "    count=0\n",
    "    for i in range(ypred.shape[0]):\n",
    "        if(ypred[i]<0):\n",
    "            ypred[i]=0\n",
    "            count+=1\n",
    "    print 'Number of Negative values predicted are ',count\n",
    "    return ypred,count\n",
    "    \n",
    "\n",
    "rf=GradientBoostingRegressor()\n",
    "split1=0.8*traind.shape[0]\n",
    "trainSplit=traind[:split1,:]\n",
    "\n",
    "testSplit=traind[split1:,:]\n",
    "labelsSplitTrain=labelsTrain[:split1]\n",
    "labelsSplitTest=labelsTrain[split1:]\n",
    "rf.fit(trainSplit,labelsSplitTrain)\n",
    "ypred=rf.predict(testSplit)\n",
    "ypred,count=replaceNegaticeValuesWithZeroAndCountThem(ypred)\n",
    "print 'trainSplit is \\n',trainSplit.shape,' and testSplit is \\n',testSplit.shape\n",
    "print 'ypred is \\n',ypred\n",
    "print 'test split is \\n',labelsSplitTest\n",
    "print 'the loss is ',findLoss(labelsSplitTest,ypred)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "rf.fit(traind,labelsTrain)\n",
    "#print 'rf.estimators_ are ',rf.estimators_\n",
    "print 'testd shape is ',testd.shape\n",
    "ypred2=rf.predict(testd)\n",
    "with open('submit2.csv', 'wb') as csvfile:\n",
    "    resultWriter= csv.writer(csvfile)\n",
    "    l=['datetime','count']\n",
    "    resultWriter.writerow(l)\n",
    "    for i in range(testd.shape[0]):\n",
    "        #print 'test[',i,'][0] is ',test[i,0]\n",
    "        l=[test[i,0],ypred2[i]]\n",
    "        resultWriter.writerow(l)\n",
    "\n",
    "allEstimators=rf.estimators_\n",
    "allEstimators=allEstimators.reshape(1,-1)\n",
    "allEstimators=allEstimators.tolist()\n",
    "\n",
    "#print '2 rf.estimators_ are ',allEstimators[0]\n",
    "\n",
    "\n",
    "\n",
    "importances=rf.feature_importances_ \n",
    "std=np.std([tree.feature_importances_ for tree in allEstimators[0]],axis=0)\n",
    "indices=np.argsort(importances)[::-1]\n",
    "print 'Feature Ranking\\n'\n",
    "\n",
    "for f in range(traind.shape[1]):\n",
    "    print(\"%d. feature %d %s (%f)\" % (f + 1, indices[f],headers[indices[f]], importances[indices[f]]))\n",
    "    \n",
    "\n",
    "            \n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_title('Feature Importances By Gradient Boosted Trees')\n",
    "ax.bar(range(traind.shape[1]),importances[indices],color=\"b\",yerr=std[indices],align='center')\n",
    "plt.xticks(range(traind.shape[1]), indices)\n",
    "ax.set_xlim([-1, traind.shape[1]])\n",
    "ax.set_xticklabels(headers[indices])\n",
    "plt.savefig('Feature Importances By Gradient Boosted Trees')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTestLocs(year,month):\n",
    "    \n",
    "    locs=[]\n",
    "    print 'In testlocs year is =',year,' month is = ',month\n",
    "    for i in range(0,test.shape[0]):\n",
    "        if test[i][0].year==year and test[i][0].month==month:\n",
    "            locs.append(i)\n",
    "    return locs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf2=RandomForestRegressor()\n",
    "set(test_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('submit3.csv','wb') as csvfile:\n",
    "    resultWriter=csv.writer(csvfile)\n",
    "    l=['datetime','count']\n",
    "    resultWriter.writerow(l)\n",
    "    for i in set(test_years):\n",
    "        for j in set(test_months):\n",
    "                testLocs=getTestLocs(i,j)\n",
    "                #print 'testLoics are ',testLocs\n",
    "                \n",
    "                testSubset1=testd[testLocs]\n",
    "                testSubset2=test[testLocs]\n",
    "                #print 'testSubset2 is ',testSubset2\n",
    "                trainLocs=np.where(train[:,0]<=min(testSubset2[:,0]))\n",
    "                trainSubset=traind[trainLocs]\n",
    "                labelsSubset=labelsTrain[trainLocs]\n",
    "                rf2.fit(trainSubset,labelsSubset)\n",
    "                ypred3=rf2.predict(testSubset1)\n",
    "                for k in range(0,testSubset2.shape[0]):\n",
    "                    l=[testSubset2[k,0],ypred3[k]]\n",
    "                    resultWriter.writerow(l)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getSplits(years,months):\n",
    "    locsTrain=[]\n",
    "    locsTest=[]\n",
    "    for i in range(0,train.shape[0]):\n",
    "            if (train[i,0].year==years[0] or train[i,0].year==years[1]) and (train[i,0].month in months):\n",
    "                locsTest.append(i)\n",
    "            else:\n",
    "                locsTrain.append(i) \n",
    "    \n",
    "    return locsTrain,locsTest\n",
    "\n",
    "def getCustomLocsTest(year,month,data):\n",
    "    locs=[]\n",
    "    for i in range(0,data.shape[0]):\n",
    "        if data[i][0].year==year and data[i][0].month==month:\n",
    "            locs.append(i)\n",
    "    return locs\n",
    "\n",
    "def crossValidate():\n",
    "        months=[12]\n",
    "        locsTrain,locsTest=getSplits([2011,2012],months)\n",
    "        \n",
    "        testSubset=traind[locsTest]\n",
    "        testSubset2=train[locsTest]\n",
    "        testLabels=labelsTrain[locsTest]\n",
    "        rf3=RandomForestRegressor(20)\n",
    "        trainSubset=traind[locsTrain]\n",
    "        trainSubset2=train[locsTrain]\n",
    "        trainLabels=labelsTrain[locsTrain]\n",
    "        \n",
    "        for i in [2011,2012]:\n",
    "            for j in months:\n",
    "                testLocs=getCustomLocsTest(i,j,testSubset2)\n",
    "                testSubset3=testSubset2[testLocs]\n",
    "                testSubset4=testSubset[testLocs]\n",
    "                testLabels4=testLabels[testLocs]\n",
    "                \n",
    "                trainLocs2=np.where(trainSubset2[:,0]<=min(testSubset3[:,0]))\n",
    "                \n",
    "                trainSubset3=trainSubset[trainLocs2]\n",
    "                trainLabels3=trainLabels[trainLocs2]\n",
    "                x1=trainSubset2[trainLocs2]\n",
    "                x2=testSubset2[testLocs]\n",
    "                \n",
    "                print 'trainSubset min is  ', min(x1[:,0]),' and max is ',max(x1[:,0])\n",
    "                print 'testSubset  min is  ', min(x2[:,0]),' and max is ',max(x2[:,0])\n",
    "                \n",
    "                rf3.fit(trainSubset3,trainLabels3)\n",
    "                \n",
    "                ypred=rf3.predict(testSubset4)\n",
    "                \n",
    "                print 'loss with year =',i,' and month = ',j,' is ',findLoss(testLabels4,ypred)\n",
    "                \n",
    "\n",
    "crossValidate() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " \n",
    "dataTrain=np.array(train)\n",
    "dataTrain.shape\n",
    "plt.plot(dataTrain[:,1],dataTrain[:,11],'*')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
